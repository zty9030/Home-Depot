{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn import pipeline, grid_search\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "#from nltk.metrics import edit_distance\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "#from nltk.stem.snowball import SnowballStemmer #0.003 improvement but takes twice as long as PorterStemmer\n",
    "#stemmer = SnowballStemmer('english')\n",
    "import re\n",
    "import random\n",
    "random.seed(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fmean_squared_error(ground_truth, predictions):\n",
    "    fmean_squared_error_ = mean_squared_error(ground_truth, predictions)**0.5\n",
    "    return fmean_squared_error_\n",
    "\n",
    "RMSE  = make_scorer(fmean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class cust_txt_col(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_whole_word(str1, str2, i_):\n",
    "    cnt = 0\n",
    "    while i_ < len(str2):\n",
    "        i_ = str2.find(str1, i_)\n",
    "        if i_ == -1:\n",
    "            return cnt\n",
    "        else:\n",
    "            cnt += 1\n",
    "            i_ += len(str1)\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_common_word(str1, str2):\n",
    "    words, cnt = str1.split(), 0\n",
    "    for word in words:\n",
    "        if str2.find(word)>=0:\n",
    "            cnt+=1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class cust_regression_vals(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, hd_searches):\n",
    "        d_col_drops=['id','relevance','search_term','product_title','product_description','product_info','brand']\n",
    "        hd_searches = hd_searches.drop(d_col_drops,axis=1).values\n",
    "        return hd_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "product = pd.read_csv('Dataset/product_stemmed.csv')\n",
    "search = pd.read_csv('Dataset/search_cleaned_stemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124428 entries, 0 to 124427\n",
      "Data columns (total 8 columns):\n",
      "prod_id                       124428 non-null int64\n",
      "product_title_unit            103 non-null object\n",
      "product_title_number          89328 non-null object\n",
      "product_title                 124428 non-null object\n",
      "product_description_unit      392 non-null object\n",
      "product_description_number    109122 non-null object\n",
      "product_description           124428 non-null object\n",
      "brand                         124428 non-null object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 8.5+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 240760 entries, 0 to 240759\n",
      "Data columns (total 6 columns):\n",
      "id                    240760 non-null int64\n",
      "product_uid           240760 non-null int64\n",
      "relevance             74067 non-null float64\n",
      "search_term_unit      151 non-null object\n",
      "search_term_number    40553 non-null object\n",
      "search_term           240630 non-null object\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 12.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product.info(),search.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = search.merge(product,left_on='product_uid',right_on='prod_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 240760 entries, 0 to 240759\n",
      "Data columns (total 14 columns):\n",
      "id                            240760 non-null int64\n",
      "product_uid                   240760 non-null int64\n",
      "relevance                     74067 non-null float64\n",
      "search_term_unit              151 non-null object\n",
      "search_term_number            40553 non-null object\n",
      "search_term                   240630 non-null object\n",
      "prod_id                       240760 non-null int64\n",
      "product_title_unit            183 non-null object\n",
      "product_title_number          176404 non-null object\n",
      "product_title                 240760 non-null object\n",
      "product_description_unit      750 non-null object\n",
      "product_description_number    215548 non-null object\n",
      "product_description           240760 non-null object\n",
      "brand                         240760 non-null object\n",
      "dtypes: float64(1), int64(3), object(10)\n",
      "memory usage: 27.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def len_of_query(s):\n",
    "    if type(s)==float:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.search_term.fillna('None',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x:len_of_query(x)).astype(np.int64)\n",
    "df_all['len_of_title'] = df_all['product_title'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_description'] = df_all['product_description'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_brand'] = df_all['brand'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title'] +\"\\t\"+df_all['product_description']\n",
    "df_all['query_in_title'] = df_all['product_info'].map(lambda x:str_whole_word(str(x).split('\\t')[0],str(x).split('\\t')[1],0))\n",
    "df_all['query_in_description'] = df_all['product_info'].map(lambda x:str_whole_word(str(x).split('\\t')[0],str(x).split('\\t')[2],0))\n",
    "df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(str(x).split('\\t')[0],str(x).split('\\t')[1]))\n",
    "df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(str(x).split('\\t')[0],str(x).split('\\t')[2]))\n",
    "df_all['ratio_title'] = df_all['word_in_title']/df_all['len_of_query']\n",
    "df_all['ratio_description'] = df_all['word_in_description']/df_all['len_of_query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 240760 entries, 0 to 240759\n",
      "Data columns (total 17 columns):\n",
      "id                      240760 non-null int64\n",
      "relevance               74067 non-null float64\n",
      "search_term             240760 non-null object\n",
      "product_title           240760 non-null object\n",
      "product_description     240760 non-null object\n",
      "brand                   240760 non-null object\n",
      "len_of_query            240760 non-null int64\n",
      "len_of_title            240760 non-null int64\n",
      "len_of_description      240760 non-null int64\n",
      "len_of_brand            240760 non-null int64\n",
      "product_info            240760 non-null object\n",
      "query_in_title          240760 non-null int64\n",
      "query_in_description    240760 non-null int64\n",
      "word_in_title           240760 non-null int64\n",
      "word_in_description     240760 non-null int64\n",
      "ratio_title             240760 non-null float64\n",
      "ratio_description       240760 non-null float64\n",
      "dtypes: float64(3), int64(9), object(5)\n",
      "memory usage: 33.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all_new = df_all.drop(['search_term_unit','search_term_number','product_title_unit','product_title_number',\n",
    "                         'product_description_unit','product_description_number','product_uid','prod_id'],axis = 1)\n",
    "df_all_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train = df_all_new[df_all_new.relevance.isnull()==False].relevance.size\n",
    "df_train = df_all_new.iloc[:num_train]\n",
    "df_test = df_all_new.iloc[num_train:]\n",
    "id_test = df_test['id']\n",
    "y_train = df_train['relevance'].values\n",
    "X_train =df_train[:]\n",
    "X_test = df_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.  ,  1.25,  1.33,  1.5 ,  1.67,  1.75,  2.  ,  2.25,  2.33,\n",
       "        2.5 ,  2.67,  2.75,  3.  ])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfr = ExtraTreesRegressor(n_estimators = 200, n_jobs = -1, random_state = 2016, verbose = 1)\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')\n",
    "tsvd = TruncatedSVD(n_components=20, random_state = 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = pipeline.Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "                    transformer_list = [ \n",
    "                        ('cst',  cust_regression_vals()),\n",
    "                        ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])),\n",
    "                        ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])),\n",
    "                        ('txt3', pipeline.Pipeline([('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])),\n",
    "                        ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))\n",
    "                        ],\n",
    "                    transformer_weights = {\n",
    "                        'cst':1.0,\n",
    "                        'txt1': 0.5,\n",
    "                        'txt2': 0.25,\n",
    "                        'txt3': 0.0,\n",
    "                        'txt4': 0.5\n",
    "                        },\n",
    "                n_jobs = -1\n",
    "                )), \n",
    "        ('rfr', rfr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   2 | elapsed:   53.1s remaining:  -17.7s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   53.1s finished\n",
      "/Users/williamz/anaconda2/lib/python2.7/site-packages/sklearn/pipeline.py:497: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n",
      "/Users/williamz/anaconda2/lib/python2.7/site-packages/sklearn/pipeline.py:497: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   35.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   35.3s finished\n",
      "/Users/williamz/anaconda2/lib/python2.7/site-packages/sklearn/pipeline.py:523: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n",
      "/Users/williamz/anaconda2/lib/python2.7/site-packages/sklearn/pipeline.py:523: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   41.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('union', FeatureUnion(n_jobs=-1,\n",
       "       transformer_list=[('cst', cust_regression_vals()), ('txt1', Pipeline(steps=[('s1', cust_txt_col(key='search_term')), ('tfidf1', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8...imators=200, n_jobs=-1, oob_score=False, random_state=2016,\n",
       "          verbose=1, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'rfr__max_features': [60], 'rfr__max_depth': [30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring=make_scorer(fmean_squared_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'rfr__max_features': [60], 'rfr__max_depth': [30]}\n",
    "model = grid_search.GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs = -1, cv = 2, verbose = 1, scoring=RMSE)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search:\n",
      "{'rfr__max_features': 60, 'rfr__max_depth': 30}\n",
      "Best CV score:\n",
      "-0.488372911151\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found by grid search:\")\n",
    "print(model.best_params_)\n",
    "print(\"Best CV score:\")\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    2.4s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('Dataset/submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

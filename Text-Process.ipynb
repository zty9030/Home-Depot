{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble import RandomForestRegressor, BaggingRegressor\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nrandom.seed(2016)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from __future__ import division\n",
    "import time\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import random\n",
    "import string\n",
    "\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "random.seed(2016)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_zeros_before_point(s):\n",
    "    if isinstance(s, str):\n",
    "        #s = re.sub('(^\\.[0-9]+)', r' 0\\1',s)\n",
    "        #s = re.sub('( \\.[0-9]+)', r' 0\\1',s)\n",
    "        #s = re.findall(\"[^0-9]*(\\.[0-9]+)\",s)\n",
    "        s = re.sub(r\"(^| )(\\.[0-9]+)\",r\" 0\\2\",s)\n",
    "        return s\n",
    "    else:\n",
    "        return 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculation(s):\n",
    "    if isinstance(s, str):\n",
    "        #num_list = ''\n",
    "        k = re.findall('[0-9]+ */ *[0-9]+', s)\n",
    "        for i in k:\n",
    "            numbers = i.split('/')\n",
    "            if float(numbers[1]) != 0:\n",
    "                calculated_num =round(float(numbers[0])/float(numbers[1]),2)\n",
    "                #num_list = num_list + ' ' + str(calculated_num)\n",
    "            else:\n",
    "                calculated_num = float(numbers[0])\n",
    "            s = re.sub(i, str(calculated_num), s)\n",
    "        return s\n",
    "    else:\n",
    "        return 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_cleaning(s):\n",
    "    if isinstance(s, str):\n",
    "        s = s.lower()\n",
    "        s = s.replace(\"$\",\" \")\n",
    "        s = s.replace(\"?\",\" \")\n",
    "        s = s.replace(\"-\",\" \")\n",
    "        s = s.replace(\"/\",\" \")\n",
    "        s = s.replace(\"\\\\\",\" \")\n",
    "        s = s.replace('&quot;', ' ')\n",
    "        s = s.replace('&amp', ' ')\n",
    "        s = s.replace('&#39', ' ')\n",
    "        s = re.sub(r\"([0-9])([a-z])\", r\"\\1 \\2\", s)\n",
    "        s = re.sub(r\"([a-z])([0-9])\", r\"\\1 \\2\", s)\n",
    "        s = s.replace(\" x \",\" xbi \")\n",
    "        s = s.replace( \"star*\", \"star\")\n",
    "        s = s.replace( \"(e*)\", \"(e)\")\n",
    "        s = s.replace( \"(e)*\", \"(e)\")\n",
    "        s = re.sub(r\"([a-z])( *)\\.( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "        s = re.sub(r\"([a-z])( *)/( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "        s = s.replace(\"*\",\" xbi \")\n",
    "        s = s.replace(\" by \",\" xbi \")\n",
    "        s = re.sub(r\"([0-9]+)( *)(inches|inch|in|')\\.?\", r\"\\1in. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(foot|feet|ft|'')\\.?\", r\"\\1ft. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(pounds|pound|lbs|lb)\\.?\", r\"\\1lb. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(square|sq) ?\\.?(feet|foot|ft)\\.?\", r\"\\1sqft. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(cubic|cu) ?\\.?(feet|foot|ft)\\.?\", r\"\\1cuft. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(gallons|gallon|gal)\\.?\", r\"\\1gal. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(ounces|ounce|oz)\\.?\", r\"\\1oz. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(centimeters|cm)\\.?\", r\"\\1cm. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(milimeters|mm)\\.?\", r\"\\1mm. \", s)\n",
    "        s = s.replace(\"Â°\",\" degrees \")\n",
    "        s = re.sub(r\"([0-9]+)( *)(degrees|degree)\\.?\", r\"\\1deg. \", s)\n",
    "        s = s.replace(\" v \",\" volts \")\n",
    "        s = re.sub(r\"([0-9]+)( *)(volts|volt)\\.?\", r\"\\1volt. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(watts|watt)\\.?\", r\"\\1watt. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(amperes|ampere|amps|amp)\\.?\", r\"\\1amp. \", s)\n",
    "        s = add_zeros_before_point(s)\n",
    "        s = calculation(s)\n",
    "        return s\n",
    "    else:\n",
    "        return 'null'          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_unit(s):\n",
    "    if isinstance(s, str):\n",
    "        s = re.findall(\"[0-9]+\\.*[0-9]*[a-z]+\\.\",s)\n",
    "        s = ' '.join(s)\n",
    "        return s\n",
    "    else:\n",
    "        return 'null'  \n",
    "def extract_numbers(s):\n",
    "    if isinstance(s, str):\n",
    "        s = re.findall(\"[0-9]+\\.*[0-9]* \",s)\n",
    "        s = ' '.join(s)\n",
    "        return s\n",
    "    else:\n",
    "        return 'null'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "def text_processing(s):\n",
    "    if isinstance(s, str):\n",
    "        #s = s.replace('*','x')\n",
    "        s = re.sub('[0-9]', ' ', s)\n",
    "        s = s.lower()\n",
    "        #s = s.replace('in.', 'inch')\n",
    "        s = s.replace('-', ' ')\n",
    "        s = s.translate(None, string.punctuation)\n",
    "        tokens = nltk.word_tokenize(s)\n",
    "        return ' '.join([stemmer.stem(word.decode('utf-8',errors='ignore')) for word in tokens])\n",
    "    else:\n",
    "         return 'null'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product = pd.read_csv('./Dataset/product.csv')\n",
    "search_term = pd.read_csv('./Dataset/search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 240760 entries, 0 to 240759\n",
      "Data columns (total 4 columns):\n",
      "id                 240760 non-null int64\n",
      "product_uid        240760 non-null int64\n",
      "search_term_new    240760 non-null object\n",
      "relevance          74067 non-null float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 9.2+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124428 entries, 0 to 124427\n",
      "Data columns (total 5 columns):\n",
      "prod_id                124428 non-null int64\n",
      "product_title          124428 non-null object\n",
      "product_description    124428 non-null object\n",
      "brand                  124428 non-null object\n",
      "attribute              86263 non-null object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 5.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term.info(),product.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search = search_term[['id','product_uid','relevance']].copy()\n",
    "#search_term['search_term_new'] = search_term['search_term_new'].apply(lambda s: add_zeros_before_point(s))\n",
    "#search_term['search_term_new'] = search_term['search_term_new'].apply(lambda s: calculation(s))\n",
    "search['search_term'] = search_term['search_term_new'].apply(lambda s: data_cleaning(s))\n",
    "search['search_term_unit'] = search_term['search_term_new'].apply(lambda s: extract_unit(s))\n",
    "search['search_term_number'] = search_term['search_term_new'].apply(lambda s: extract_numbers(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 240760 entries, 0 to 240759\n",
      "Data columns (total 6 columns):\n",
      "id                    240760 non-null int64\n",
      "product_uid           240760 non-null int64\n",
      "relevance             74067 non-null float64\n",
      "search_term           240760 non-null object\n",
      "search_term_unit      240760 non-null object\n",
      "search_term_number    240760 non-null object\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 12.9+ MB\n"
     ]
    }
   ],
   "source": [
    "search.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search['search_term_stemmed'] = search.search_term.apply(lambda s: text_processing(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search.drop('search_term',axis=1).to_csv('./Dataset/search_cleaned_stemmed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product_new = product[['prod_id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#product['product_title'] = product['product_title'].apply(lambda s: add_zeros_before_point(s))\n",
    "#product['product_title'] = product['product_title'].apply(lambda s: calculation(s)) \n",
    "product_new['product_title'] = product['product_title'].apply(lambda s: data_cleaning(s))\n",
    "product_new['product_title_unit'] = product['product_title'].apply(lambda s: extract_unit(s)) \n",
    "product_new['product_title_number'] = product['product_title'].apply(lambda s: extract_numbers(s)) \n",
    "product_new['product_title_stemmed'] = product['product_title'].apply(lambda s: text_processing(s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#product['product_description'] = product['product_description'].apply(lambda s: add_zeros_before_point(s))\n",
    "#product['product_description'] = product['product_description'].apply(lambda s: calculation(s)) \n",
    "product_new['product_description'] = product['product_description'].apply(lambda s: data_cleaning(s))\n",
    "product_new['product_description_unit'] = product['product_description'].apply(lambda s: extract_unit(s)) \n",
    "product_new['product_description_number'] = product['product_description'].apply(lambda s: extract_numbers(s)) \n",
    "product_new['product_description_stemmed'] = product['product_description'].apply(lambda s: text_processing(s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#not use\n",
    "'''#product['attribute'] = product['attribute'].apply(lambda s: add_zeros_before_point(s))\n",
    "#product['attribute'] = product['attribute'].apply(lambda s: calculation(s)) \n",
    "product_new['attribute'] = product['attribute'].apply(lambda s: data_cleaning(s))\n",
    "product_new['attribute_unit'] = product['attribute'].apply(lambda s: extract_unit(s)) \n",
    "product_new['attribute_number'] = product['attribute'].apply(lambda s: extract_numbers(s)) \n",
    "product_new['attribute_stemmed'] = product['attribute'].apply(lambda s: text_processing(s)) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "product_new['brand_stemmed'] = product['brand'].apply(lambda s: text_processing(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124428 entries, 0 to 124427\n",
      "Data columns (total 10 columns):\n",
      "prod_id                        124428 non-null int64\n",
      "product_title                  124428 non-null object\n",
      "product_title_unit             124428 non-null object\n",
      "product_title_number           124428 non-null object\n",
      "product_title_stemmed          124428 non-null object\n",
      "product_description            124428 non-null object\n",
      "product_description_unit       124428 non-null object\n",
      "product_description_number     124428 non-null object\n",
      "product_description_stemmed    124428 non-null object\n",
      "brand_stemmed                  124428 non-null object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 10.4+ MB\n"
     ]
    }
   ],
   "source": [
    "product_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product_new.drop(['product_title','product_description'],axis=1).to_csv('Dataset/product_stemmed.csv',index=False,encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 240760 entries, 0 to 240759\n",
      "Data columns (total 7 columns):\n",
      "ï»¿id                    240760 non-null int64\n",
      "product_uid            240760 non-null int64\n",
      "search_term_new        240760 non-null object\n",
      "relevance              74067 non-null float64\n",
      "search_term_unit       240760 non-null object\n",
      "search_term_number     240760 non-null object\n",
      "search_term_stemmed    240760 non-null object\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 14.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame()\n",
    "data_merged = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product = product.rename(columns={'pro_id': 'product_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'product_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-254-fc10347af371>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# mapping search term & product\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch_term\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_term\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproduct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'product_uid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'product_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\ipython1\\lib\\site-packages\\pandas\\tools\\merge.pyc\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[0;32m     32\u001b[0m                          \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                          copy=copy, indicator=indicator)\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ipython1\\lib\\site-packages\\pandas\\tools\\merge.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[0;32m    188\u001b[0m         (self.left_join_keys,\n\u001b[0;32m    189\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ipython1\\lib\\site-packages\\pandas\\tools\\merge.pyc\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m                         \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                             \u001b[1;31m# avoid key upcast in corner case (length-0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ipython1\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1967\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1968\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1969\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1971\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ipython1\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1974\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1975\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1976\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1978\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ipython1\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1091\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1092\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ipython1\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3210\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3211\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3212\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3213\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ipython1\\lib\\site-packages\\pandas\\core\\index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   1757\u001b[0m                                  'backfill or nearest lookups')\n\u001b[0;32m   1758\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1759\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3979)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3843)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12265)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12216)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'product_id'"
     ]
    }
   ],
   "source": [
    "# mapping search term & product\n",
    "data = search_term.copy()\n",
    "data= pd.merge(search_term, product, left_on='product_uid', right_on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_common_word(str1, str2):\n",
    "    return sum(int(str2.find(word)>=0) for word in str1.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def common_word_percent(str1, str2):\n",
    "    count = 0\n",
    "    if len(str1) != 0:\n",
    "        for word in str1.lower().split():\n",
    "            if str2.lower().find(word) >= 0:\n",
    "                count += 1\n",
    "            else:\n",
    "                count = count\n",
    "            #count_sum = count_sum + count\n",
    "        percent_included = count/(len(str1.lower().split()))\n",
    "        return percent_included\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['word_in_title'] = data[['product_title_stemmed','search_term_stemmed']].apply(lambda s:str_common_word(s['search_term_stemmed'],\n",
    "                                                                                                            s['product_title_stemmed']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['word_in_desc'] = data[['product_description_stemmed','search_term_stemmed']].apply(lambda s:str_common_word(s['search_term_stemmed'],\n",
    "                                                                                                            s['product_description_stemmed']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['word_in_attr'] = data[['attribute_stemmed','search_term_stemmed']].apply(lambda s:str_common_word(s['search_term_stemmed'],\n",
    "                                                                                                            s['attribute_stemmed']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['word_in_brand'] = data[['brand_stemmed','search_term_stemmed']].apply(lambda s:str_common_word(s['search_term_stemmed'],\n",
    "                                                                                                            s['brand_stemmed']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['percent_in_title'] = data[['product_title_stemmed','search_term_stemmed']].apply(lambda s:common_word_percent(s['search_term_stemmed'],\n",
    "                                                                                                            s['product_title_stemmed']),axis=1)\n",
    "data['percent_in_desc'] = data[['product_description_stemmed','search_term_stemmed']].apply(lambda s:common_word_percent(s['search_term_stemmed'],\n",
    "                                                                                                            s['product_description_stemmed']),axis=1)\n",
    "data['percent_in_attr'] = data[['attribute_stemmed','search_term_stemmed']].apply(lambda s:common_word_percent(s['search_term_stemmed'],\n",
    "                                                                                                            s['attribute_stemmed']),axis=1)\n",
    "data['percent_in_brand'] = data[['brand_stemmed','search_term_stemmed']].apply(lambda s:common_word_percent(s['search_term_stemmed'],\n",
    "                                                                                                            s['brand_stemmed']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['brand_in_search'] =  data[['brand_stemmed','search_term_stemmed']].apply(lambda s:common_word_percent(s['brand_stemmed'],\n",
    "                                                                                                           s['search_term_stemmed']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# match unit\n",
    "data['unit_all'] = data.search_term_unit + '\\t' + data.product_title_unit + '\\t' + data.product_description_unit + '\\t' + data.attribute_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unit_title(s):\n",
    "    title = s.split('\\t')[1]\n",
    "    search = s.split('\\t')[0]\n",
    "    if search == '':\n",
    "        return 1\n",
    "    elif search in title:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "def unit_desc(s):\n",
    "    title = s.split('\\t')[2]\n",
    "    search = s.split('\\t')[0]\n",
    "    if search == '':\n",
    "        return 1\n",
    "    elif search in title:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0    \n",
    "def unit_attr(s):\n",
    "    title = s.split('\\t')[3]\n",
    "    search = s.split('\\t')[0]\n",
    "    if search == '':\n",
    "        return 1\n",
    "    elif search in title:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['unit_title'] = data.unit_all.apply(lambda s:unit_title(s))\n",
    "data['unit_desc'] = data.unit_all.apply(lambda s:unit_desc(s))\n",
    "data['unit_attr'] = data.unit_all.apply(lambda s:unit_attr(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# match numbers\n",
    "data['num_all'] = data.search_term_number + '\\t' + data.product_title_number + '\\t'+data.product_description_number+'\\t'+data.attribute_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_title(s):\n",
    "    title = s.split('\\t')[1]\n",
    "    search = s.split('\\t')[0]\n",
    "    if search == '':\n",
    "        return 1\n",
    "    elif len(search.split()) == 1:\n",
    "        num = search.split()[0] in title.split()\n",
    "        if num == True:\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "    elif search in title:\n",
    "        return 3\n",
    "    else:\n",
    "        return 0\n",
    "def num_desc(s):\n",
    "    title = s.split('\\t')[2]\n",
    "    search = s.split('\\t')[0]\n",
    "    if search == '':\n",
    "        return 1\n",
    "    elif len(search.split()) == 1:\n",
    "        num = search.split()[0] in title.split()\n",
    "        if num == True:\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "    elif search in title:\n",
    "        return 3\n",
    "    else:\n",
    "        return 0\n",
    "def num_attr(s):\n",
    "    title = s.split('\\t')[3]\n",
    "    search = s.split('\\t')[0]\n",
    "    if search == '':\n",
    "        return 1\n",
    "    elif len(search.split()) == 1:\n",
    "        num = search.split()[0] in title.split()\n",
    "        if num == True:\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "    elif search in title:\n",
    "        return 3\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['num_title'] = data.num_all.apply(lambda s:num_title(s))\n",
    "data['num_desc'] = data.num_all.apply(lambda s:num_desc(s))\n",
    "data['num_attr'] = data.num_all.apply(lambda s:num_attr(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find common word \n",
    "def common_word(str1, str2):\n",
    "    content =''\n",
    "    for word in str1.split():\n",
    "        if word in str2.split():\n",
    "            content = content + ' ' + word\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# common word in title\n",
    "data['title_search'] = data['search_term_stemmed'] + '\\t' + data['product_title_stemmed']\n",
    "data['word_in_title_tfidf'] = data['title_search'].map(lambda x:common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "search_idf_list = list(data['word_in_title_tfidf']) \n",
    "title_stemmed_list = list(data['product_title_stemmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# common word in desc\n",
    "data['desc_search'] = data['search_term_stemmed'] + '\\t' + data['product_description_stemmed']\n",
    "data['word_in_desc_tfidf'] = data['desc_search'].map(lambda x:common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "search_idf_list_desc = list(data['word_in_desc_tfidf']) \n",
    "desc_stemmed_list = list(data['product_description_stemmed'])\n",
    "# common word in attr\n",
    "data['attr_search'] = data['search_term_stemmed'] + '\\t' + data['attribute_stemmed']\n",
    "data['word_in_attr_tfidf'] = data['attr_search'].map(lambda x:common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "search_idf_list_attr = list(data['word_in_attr_tfidf']) \n",
    "attr_stemmed_list = list(data['attribute_stemmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124428, 21721)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf for title\n",
    "tfidf = TfidfVectorizer()\n",
    "tfs = tfidf.fit_transform(product['product_title_stemmed'])\n",
    "feature_names = tfidf.get_feature_names()\n",
    "tfs.shape\n",
    "# tfidf for desc\n",
    "tfidf_desc = TfidfVectorizer()\n",
    "tfs_desc = tfidf_desc.fit_transform(product['product_description_stemmed'])\n",
    "feature_names_desc = tfidf_desc.get_feature_names()\n",
    "tfs_desc.shape\n",
    "# tfidf for attr\n",
    "tfidf_attr = TfidfVectorizer()\n",
    "tfs_attr = tfidf_attr.fit_transform(product['attribute_stemmed'])\n",
    "feature_names_attr = tfidf_attr.get_feature_names()\n",
    "tfs_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# title\n",
    "weight_list =[]\n",
    "for i in range(len(data)):\n",
    "    if search_idf_list[i].split() != []:\n",
    "        weight = 0\n",
    "        sum_weight = 0\n",
    "        for word in search_idf_list[i].split():\n",
    "            if len(word) > 1:\n",
    "                word_index = feature_names.index(word)\n",
    "                response = tfidf.transform([title_stemmed_list[i]])\n",
    "                weight = response[0,word_index]\n",
    "                sum_weight += weight\n",
    "    else: sum_weight = 0\n",
    "    weight_list += [sum_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# desc\n",
    "weight_list_desc =[]\n",
    "for i in range(len(search_idf_list_desc)):\n",
    "    if search_idf_list_desc[i].split() != []:\n",
    "        weight = 0\n",
    "        sum_weight = 0\n",
    "        for word in search_idf_list_desc[i].split():\n",
    "            if len(word) > 1:\n",
    "                word_index = feature_names_desc.index(word)\n",
    "                response = tfidf_desc.transform([desc_stemmed_list[i]])\n",
    "                weight = response[0,word_index]\n",
    "                sum_weight += weight\n",
    "    else: sum_weight = 0\n",
    "    weight_list_desc += [sum_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# attr\n",
    "weight_list_attr =[]\n",
    "for i in range(len(search_idf_list_attr)):\n",
    "    if search_idf_list_attr[i].split() != []:\n",
    "        weight = 0\n",
    "        sum_weight = 0\n",
    "        for word in search_idf_list_attr[i].split():\n",
    "            if len(word) > 1:\n",
    "                word_index = feature_names_attr.index(word)\n",
    "                response = tfidf_attr.transform([attr_stemmed_list[i]])\n",
    "                weight = response[0,word_index]\n",
    "                sum_weight += weight\n",
    "    else: sum_weight = 0\n",
    "    weight_list_attr += [sum_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tfidf_desc'] = weight_list_desc\n",
    "data['tfidf_attr'] = weight_list_attr\n",
    "features['tfidf_desc'] = weight_list_desc\n",
    "features['tfidf_attr'] = weight_list_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.to_csv('./features_with_tfidf_attr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tfidf_title'] = weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = data[['word_in_title','word_in_desc','word_in_attr','word_in_brand','percent_in_title',\n",
    "                'percent_in_desc','percent_in_attr','percent_in_brand','brand_in_search',\n",
    "                'unit_title','unit_desc','unit_attr','num_title','num_desc','num_attr',\n",
    "                'tfidf_title']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train & test\n",
    "num_train = 74067\n",
    "train_x = features.iloc[:num_train]\n",
    "test_x= features.iloc[num_train:]\n",
    "train_y = data['relevance'].iloc[:num_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "clf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\n",
    "clf.fit(train_x, train_y)\n",
    "y_pred = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction.to_csv('./submission_14_tfidf_without_attr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.to_csv('./features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240760, 6910)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf for search terms\n",
    "#tfidf_search = TfidfVectorizer()\n",
    "#tfs_search = tfidf_search.fit_transform(data['search_term_stemmed'])\n",
    "#feature_names_search = tfidf_search.get_feature_names()\n",
    "#tfs_search.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "weight_list =[]\n",
    "for i in range(len(data)):\n",
    "    if search_idf_list[i].split() != []:\n",
    "        weight = 0\n",
    "        sum_weight = 0\n",
    "        for word in search_idf_list[i].split():\n",
    "            if len(word) > 1:\n",
    "                word_index = feature_names.index(word)\n",
    "                response = tfidf.transform([title_stemmed_list[i]])\n",
    "                weight = response[0,word_index]\n",
    "                word_index_search = feature_names_search.index(word)\n",
    "                response_search = tfidf_search.transform([search_idf_list[i]])\n",
    "                weight_search = response_search[0,word_index_search]\n",
    "                weight_new = weight * weight_search\n",
    "                sum_weight += weight_new\n",
    "    else: sum_weight = 0\n",
    "    weight_list += [sum_weight]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data['tfidf_title_times_search'] = weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features['tfidf_title_times_search'] = weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testing gradient boosting regression\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,max_depth=1,\n",
    "                                random_state=0, loss='ls').fit(train_x, train_y)\n",
    "prediction = est.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction.to_csv('./submission_13.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
